{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71debbed",
   "metadata": {},
   "source": [
    "# Dataset Balancing & Model Training (Phase 2)\n",
    "\n",
    "## SECTION 1: Setup & Minimal Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8029d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Minimal imports loaded\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "print('âœ“ Minimal imports loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160872f",
   "metadata": {},
   "source": [
    "## SECTION 2: Load & Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5df269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loading dataset from: ../DATA_CLEANED/processed/engineered_features_scaled.csv\n",
      "Shape: (71050, 23)\n",
      "Columns: ['fire', 'latitude', 'longitude', 'prec_p10', 'tmax_mean', 'tmax_std', 'tmin_mean', 'tmax_max', 't_range', 'gridcode'] ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fire</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>prec_p10</th>\n",
       "      <th>tmax_mean</th>\n",
       "      <th>tmax_std</th>\n",
       "      <th>tmin_mean</th>\n",
       "      <th>tmax_max</th>\n",
       "      <th>t_range</th>\n",
       "      <th>gridcode</th>\n",
       "      <th>...</th>\n",
       "      <th>ref_bulk</th>\n",
       "      <th>moisture_retention</th>\n",
       "      <th>texture_soter_M</th>\n",
       "      <th>elevation</th>\n",
       "      <th>terrain_roughness_index</th>\n",
       "      <th>bsat</th>\n",
       "      <th>ruggedness</th>\n",
       "      <th>teb</th>\n",
       "      <th>texture_soter_C</th>\n",
       "      <th>tcarbon_eq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36.395833</td>\n",
       "      <td>6.962500</td>\n",
       "      <td>1.180415</td>\n",
       "      <td>-0.807072</td>\n",
       "      <td>0.083139</td>\n",
       "      <td>-0.818977</td>\n",
       "      <td>-0.989303</td>\n",
       "      <td>-0.72555</td>\n",
       "      <td>-1.399386</td>\n",
       "      <td>...</td>\n",
       "      <td>1.393705</td>\n",
       "      <td>0.761360</td>\n",
       "      <td>0.760525</td>\n",
       "      <td>1.474982</td>\n",
       "      <td>-1.410052</td>\n",
       "      <td>0.738670</td>\n",
       "      <td>1.292073</td>\n",
       "      <td>0.896769</td>\n",
       "      <td>-0.412065</td>\n",
       "      <td>0.622275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>37.312500</td>\n",
       "      <td>9.654167</td>\n",
       "      <td>0.747104</td>\n",
       "      <td>-0.807072</td>\n",
       "      <td>-1.262777</td>\n",
       "      <td>-0.818977</td>\n",
       "      <td>-1.377678</td>\n",
       "      <td>-0.72555</td>\n",
       "      <td>-1.271628</td>\n",
       "      <td>...</td>\n",
       "      <td>1.706704</td>\n",
       "      <td>0.256036</td>\n",
       "      <td>0.760525</td>\n",
       "      <td>-0.816444</td>\n",
       "      <td>0.821806</td>\n",
       "      <td>0.512056</td>\n",
       "      <td>-0.462006</td>\n",
       "      <td>0.507068</td>\n",
       "      <td>-0.412065</td>\n",
       "      <td>2.851375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>36.095833</td>\n",
       "      <td>4.854167</td>\n",
       "      <td>1.491641</td>\n",
       "      <td>-0.807072</td>\n",
       "      <td>0.723202</td>\n",
       "      <td>-0.818977</td>\n",
       "      <td>-0.455287</td>\n",
       "      <td>-0.72555</td>\n",
       "      <td>-0.249563</td>\n",
       "      <td>...</td>\n",
       "      <td>1.706704</td>\n",
       "      <td>0.334186</td>\n",
       "      <td>0.760525</td>\n",
       "      <td>1.652124</td>\n",
       "      <td>0.821806</td>\n",
       "      <td>0.738670</td>\n",
       "      <td>-0.462006</td>\n",
       "      <td>1.119456</td>\n",
       "      <td>-0.412065</td>\n",
       "      <td>1.956702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>36.645833</td>\n",
       "      <td>4.229167</td>\n",
       "      <td>1.184564</td>\n",
       "      <td>-0.807072</td>\n",
       "      <td>-0.597575</td>\n",
       "      <td>-0.818977</td>\n",
       "      <td>-1.183490</td>\n",
       "      <td>-0.72555</td>\n",
       "      <td>-1.399386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379963</td>\n",
       "      <td>0.327643</td>\n",
       "      <td>0.760525</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>-1.439894</td>\n",
       "      <td>0.058826</td>\n",
       "      <td>3.383477</td>\n",
       "      <td>-0.717708</td>\n",
       "      <td>-0.412065</td>\n",
       "      <td>-0.863791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36.637500</td>\n",
       "      <td>7.662500</td>\n",
       "      <td>0.928930</td>\n",
       "      <td>-0.807072</td>\n",
       "      <td>-0.670989</td>\n",
       "      <td>-0.818977</td>\n",
       "      <td>-0.843662</td>\n",
       "      <td>-0.72555</td>\n",
       "      <td>-1.399386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350371</td>\n",
       "      <td>-0.041119</td>\n",
       "      <td>0.760525</td>\n",
       "      <td>-0.816444</td>\n",
       "      <td>0.821806</td>\n",
       "      <td>0.766997</td>\n",
       "      <td>-0.462006</td>\n",
       "      <td>0.340053</td>\n",
       "      <td>-0.412065</td>\n",
       "      <td>0.667767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fire   latitude  longitude  prec_p10  tmax_mean  tmax_std  tmin_mean  \\\n",
       "0     0  36.395833   6.962500  1.180415  -0.807072  0.083139  -0.818977   \n",
       "1     0  37.312500   9.654167  0.747104  -0.807072 -1.262777  -0.818977   \n",
       "2     0  36.095833   4.854167  1.491641  -0.807072  0.723202  -0.818977   \n",
       "3     0  36.645833   4.229167  1.184564  -0.807072 -0.597575  -0.818977   \n",
       "4     0  36.637500   7.662500  0.928930  -0.807072 -0.670989  -0.818977   \n",
       "\n",
       "   tmax_max  t_range  gridcode  ...  ref_bulk  moisture_retention  \\\n",
       "0 -0.989303 -0.72555 -1.399386  ...  1.393705            0.761360   \n",
       "1 -1.377678 -0.72555 -1.271628  ...  1.706704            0.256036   \n",
       "2 -0.455287 -0.72555 -0.249563  ...  1.706704            0.334186   \n",
       "3 -1.183490 -0.72555 -1.399386  ... -0.379963            0.327643   \n",
       "4 -0.843662 -0.72555 -1.399386  ...  0.350371           -0.041119   \n",
       "\n",
       "   texture_soter_M  elevation  terrain_roughness_index      bsat  ruggedness  \\\n",
       "0         0.760525   1.474982                -1.410052  0.738670    1.292073   \n",
       "1         0.760525  -0.816444                 0.821806  0.512056   -0.462006   \n",
       "2         0.760525   1.652124                 0.821806  0.738670   -0.462006   \n",
       "3         0.760525   1.314982                -1.439894  0.058826    3.383477   \n",
       "4         0.760525  -0.816444                 0.821806  0.766997   -0.462006   \n",
       "\n",
       "        teb  texture_soter_C  tcarbon_eq  \n",
       "0  0.896769        -0.412065    0.622275  \n",
       "1  0.507068        -0.412065    2.851375  \n",
       "2  1.119456        -0.412065    1.956702  \n",
       "3 -0.717708        -0.412065   -0.863791  \n",
       "4  0.340053        -0.412065    0.667767  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (71050, 22) | Target shape: (71050,)\n"
     ]
    }
   ],
   "source": [
    "# Try to locate a prepared features CSV automatically\n",
    "possible_paths = [\n",
    "    '../DATA_CLEANED/processed/engineered_features_scaled.csv',\n",
    "    '../DATA_CLEANED/processed/engineered_features.csv',\n",
    "    '../DATA_CLEANED/FIRE_CUT/fire_filtered.csv'\n",
    "]\n",
    "\n",
    "data_path = None\n",
    "for p in possible_paths:\n",
    "    if os.path.exists(p):\n",
    "        data_path = p\n",
    "        break\n",
    "\n",
    "if data_path is None:\n",
    "    print('âš  No dataset found. Please set `data_path` to your features CSV.')\n",
    "    df = None\n",
    "else:\n",
    "    print(f'âœ“ Loading dataset from: {data_path}')\n",
    "    df = pd.read_csv(data_path)\n",
    "    print('Shape:', df.shape)\n",
    "    print('Columns:', list(df.columns)[:10], '...')\n",
    "    display(df.head())\n",
    "\n",
    "# Infer target column\n",
    "TARGET_CANDIDATES = ['fire', 'label', 'target']\n",
    "target_col = None\n",
    "if df is not None:\n",
    "    for c in TARGET_CANDIDATES:\n",
    "        if c in df.columns:\n",
    "            target_col = c\n",
    "            break\n",
    "    if target_col is None:\n",
    "        print('âš  Could not infer a target column from candidates:', TARGET_CANDIDATES)\n",
    "\n",
    "# Separate features and target\n",
    "if df is not None and target_col is not None:\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    print('Features shape:', X.shape, '| Target shape:', y.shape)\n",
    "else:\n",
    "    X, y = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a8557",
   "metadata": {},
   "source": [
    "## SECTION 3: Stratified Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98b3cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (56840, 22) | Test: (14210, 22)\n",
      "Imbalance ratio (train): 4.0\n"
     ]
    }
   ],
   "source": [
    "if X is None or y is None:\n",
    "    print('âš  Split skipped: define `X` and `y` in Section 2.')\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print('Train:', X_train.shape, '| Test:', X_test.shape)\n",
    "\n",
    "    # Class ratio for info\n",
    "    class_counts = y_train.value_counts()\n",
    "    majority = class_counts.max()\n",
    "    minority = class_counts.min()\n",
    "    imbalance_ratio = majority / minority if minority > 0 else np.inf\n",
    "    print('Imbalance ratio (train):', round(imbalance_ratio, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf2ccd",
   "metadata": {},
   "source": [
    "## SECTION 7: EVALUATE & SELECT BEST MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464e37db",
   "metadata": {},
   "source": [
    "## SECTION 2: LOAD & EXPLORE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, BalancedRandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, auc, f1_score, precision_score, recall_score,\n",
    "    balanced_accuracy_score, accuracy_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import xgboost as xgb\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print('âœ“ Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db19b74e",
   "metadata": {},
   "source": [
    "## SECTION 1: SETUP & LIBRARY IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fffca1",
   "metadata": {},
   "source": [
    "# PHASE 2: DATASET BALANCING & MODEL TRAINING\n",
    "\n",
    "## Fire Detection Model: Comprehensive ML Pipeline\n",
    "\n",
    "This notebook implements dataset balancing and model training for fire detection in Algeria-Tunisia.\n",
    "\n",
    "**Key Objectives:**\n",
    "1. Load engineered features from Phase 1\n",
    "2. Analyze and visualize class imbalance\n",
    "3. Implement multiple balancing strategies (SMOTE, SMOTETomek, Class Weights)\n",
    "4. Train and evaluate 5 diverse models\n",
    "5. Perform cross-validation and select best model\n",
    "6. Save results and produce final summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc693a9",
   "metadata": {},
   "source": [
    "## SECTION 4: Apply Balancing Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63a0415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "APPLYING BALANCING STRATEGIES\n",
      "======================================================================\n",
      "1. SMOTE: 56,840 â†’ 90,944 samples\n",
      "2. SMOTETomek: 56,840 â†’ 88,660 samples\n",
      "3. Class Weights: Non-Fire=0.62, Fire=2.50\n"
     ]
    }
   ],
   "source": [
    "# Ensure required variables exist\n",
    "required = ['X_train', 'y_train']\n",
    "if not all(name in globals() and globals()[name] is not None for name in required):\n",
    "    print('âš  Balancing skipped: run Sections 2â€“3 to define X_train/y_train.')\n",
    "else:\n",
    "    # Import here to keep top imports minimal\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "    print('=' * 70)\n",
    "    print('APPLYING BALANCING STRATEGIES')\n",
    "    print('=' * 70)\n",
    "\n",
    "    # Strategy 1: SMOTE\n",
    "    smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    print(f'1. SMOTE: {len(y_train):,} â†’ {len(y_train_smote):,} samples')\n",
    "\n",
    "    # Strategy 2: SMOTETomek\n",
    "    smo_tomek = SMOTETomek(random_state=42)\n",
    "    X_train_smo_tomek, y_train_smo_tomek = smo_tomek.fit_resample(X_train, y_train)\n",
    "    print(f'2. SMOTETomek: {len(y_train):,} â†’ {len(y_train_smo_tomek):,} samples')\n",
    "\n",
    "    # Strategy 3: Class Weights\n",
    "    classes = np.unique(y_train)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "    class_weight_dict = {int(cls): float(w) for cls, w in zip(classes, class_weights)}\n",
    "    print(f\"3. Class Weights: Non-Fire={class_weight_dict.get(0):.2f}, Fire={class_weight_dict.get(1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b9c60",
   "metadata": {},
   "source": [
    "## SECTION 5: Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561d12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING 5 MODELS Ã— 3 STRATEGIES = 15 VARIANTS\n",
      "======================================================================\n",
      "\n",
      "SMOTE:\n",
      "  â€¢ Logistic Regression... âœ“\n",
      "  â€¢ Random Forest... âœ“\n",
      "  â€¢ Balanced RF... âœ“\n",
      "  â€¢ SVM... "
     ]
    }
   ],
   "source": [
    "# Check that balancing outputs exist\n",
    "needed = ['X_train_smote', 'y_train_smote', 'X_train_smo_tomek', 'y_train_smo_tomek', 'class_weight_dict']\n",
    "if not all(name in globals() for name in needed):\n",
    "    print('âš  Training skipped: run Section 4 to generate balanced datasets and class weights.')\n",
    "else:\n",
    "    print('\\n' + '=' * 70)\n",
    "    print('TRAINING 5 MODELS Ã— 3 STRATEGIES = 15 VARIANTS')\n",
    "    print('=' * 70)\n",
    "\n",
    "    # Define models\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1),\n",
    "        'Balanced RF': BalancedRandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1),\n",
    "        'SVM': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "    }\n",
    "\n",
    "    # Strategy datasets\n",
    "    strategies = {\n",
    "        'SMOTE': (X_train_smote, y_train_smote),\n",
    "        'SMOTETomek': (X_train_smo_tomek, y_train_smo_tomek),\n",
    "        'Class Weights': (X_train, y_train, class_weight_dict)\n",
    "    }\n",
    "\n",
    "    trained_models = {}\n",
    "    predictions_on_test = {}\n",
    "\n",
    "    for strategy_name, data in strategies.items():\n",
    "        print(f'\\n{strategy_name}:')\n",
    "        if strategy_name == 'Class Weights':\n",
    "            X_s, y_s, weights = data\n",
    "        else:\n",
    "            X_s, y_s = data\n",
    "            weights = None\n",
    "\n",
    "        for model_name, base_model in models.items():\n",
    "            print(f'  â€¢ {model_name}...', end=' ', flush=True)\n",
    "            m = base_model.__class__(**base_model.get_params())\n",
    "            if strategy_name == 'Class Weights' and hasattr(m, 'class_weight'):\n",
    "                params = m.get_params()\n",
    "                params['class_weight'] = weights\n",
    "                m = m.__class__(**params)\n",
    "\n",
    "            m.fit(X_s, y_s)\n",
    "            y_pred = m.predict(X_test)\n",
    "            y_pred_proba = m.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            key = f'{model_name}_{strategy_name}'\n",
    "            trained_models[key] = m\n",
    "            predictions_on_test[key] = {\n",
    "                'y_pred': y_pred,\n",
    "                'y_pred_proba': y_pred_proba,\n",
    "                'model': model_name,\n",
    "                'strategy': strategy_name\n",
    "            }\n",
    "            print('âœ“')\n",
    "\n",
    "    print(f'\\nâœ“ All models trained: {len(trained_models)} variants')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c19418",
   "metadata": {},
   "source": [
    "## SECTION 6: Evaluate & Select Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ccfccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure predictions exist\n",
    "if 'predictions_on_test' not in globals() or len(predictions_on_test) == 0:\n",
    "    print('âš  Evaluation skipped: run Section 5 to train models and generate predictions.')\n",
    "else:\n",
    "    print('\\n' + '=' * 70)\n",
    "    print('EVALUATING ALL MODELS')\n",
    "    print('=' * 70)\n",
    "\n",
    "    rows = []\n",
    "    for key, preds in predictions_on_test.items():\n",
    "        y_pred = preds['y_pred']\n",
    "        y_pred_proba = preds['y_pred_proba']\n",
    "        rows.append({\n",
    "            'Model': preds['model'],\n",
    "            'Strategy': preds['strategy'],\n",
    "            'Accuracy': accuracy_score(y_test, y_pred),\n",
    "            'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "            'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "            'F1': f1_score(y_test, y_pred, zero_division=0),\n",
    "            'ROC-AUC': roc_auc_score(y_test, y_pred_proba)\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(rows)\n",
    "    print('\\nTop 5 Models by ROC-AUC:')\n",
    "    print(results_df.nlargest(5, 'ROC-AUC')[['Model', 'Strategy', 'Accuracy', 'Recall', 'ROC-AUC']])\n",
    "\n",
    "    best_idx = results_df['ROC-AUC'].idxmax()\n",
    "    best_model_info = results_df.loc[best_idx]\n",
    "    best_model_key = f\"{best_model_info['Model']}_{best_model_info['Strategy']}\"\n",
    "    best_model_trained = trained_models[best_model_key]\n",
    "    best_preds = predictions_on_test[best_model_key]\n",
    "\n",
    "    print(f\"\\nðŸ† BEST MODEL: {best_model_info['Model']} + {best_model_info['Strategy']}\")\n",
    "    print(f\"   ROC-AUC: {best_model_info['ROC-AUC']:.4f}\")\n",
    "    print(f\"   Recall: {best_model_info['Recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e6b40",
   "metadata": {},
   "source": [
    "## SECTION 5A: Single-Model Timing (KNN, Decision Tree, Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf75e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Tuple\n",
    "\n",
    "# Utility: choose training set per balancing mode\n",
    "BALANCING_MODE = 'none'  # options: 'none', 'smote', 'smote_tomek', 'class_weights'\n",
    "\n",
    "def get_train_data(mode: str) -> Tuple[pd.DataFrame, pd.Series, dict | None]:\n",
    "    if mode == 'smote':\n",
    "        if 'X_train_smote' in globals():\n",
    "            return X_train_smote, y_train_smote, None\n",
    "        else:\n",
    "            print('âš  SMOTE data not found. Falling back to none.')\n",
    "            return X_train, y_train, None\n",
    "    if mode == 'smote_tomek':\n",
    "        if 'X_train_smo_tomek' in globals():\n",
    "            return X_train_smo_tomek, y_train_smo_tomek, None\n",
    "        else:\n",
    "            print('âš  SMOTETomek data not found. Falling back to none.')\n",
    "            return X_train, y_train, None\n",
    "    if mode == 'class_weights':\n",
    "        if 'class_weight_dict' in globals():\n",
    "            return X_train, y_train, class_weight_dict\n",
    "        else:\n",
    "            print('âš  class_weight_dict not found. Falling back to none.')\n",
    "            return X_train, y_train, None\n",
    "    return X_train, y_train, None\n",
    "\n",
    "# Utility: time fit and predict\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def time_model_fit_predict(model, X_tr, y_tr, X_te, y_te):\n",
    "    t0 = time.perf_counter()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    t_fit = time.perf_counter() - t0\n",
    "\n",
    "    t1 = time.perf_counter()\n",
    "    y_pred = model.predict(X_te)\n",
    "    t_pred = time.perf_counter() - t1\n",
    "\n",
    "    # proba or decision\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_te)[:, 1]\n",
    "    elif hasattr(model, 'decision_function'):\n",
    "        y_score = model.decision_function(X_te)\n",
    "        # Map to [0,1] via a simple min-max if needed\n",
    "        y_proba = (y_score - y_score.min()) / (y_score.max() - y_score.min() + 1e-9)\n",
    "    else:\n",
    "        y_proba = None\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_te, y_pred),\n",
    "        'precision': precision_score(y_te, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_te, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_te, y_pred, zero_division=0),\n",
    "        'roc_auc': roc_auc_score(y_te, y_proba) if y_proba is not None else None,\n",
    "    }\n",
    "    return metrics, t_fit, t_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6787382",
   "metadata": {},
   "source": [
    "### Run: KNN (timed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecf40372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN using training set: (90944, 22), BALANCING_MODE=smote\n",
      "Fit time:  0.02s (KNN fit is typically trivial)\n",
      "Pred time: 2.53s (KNN prediction scales with train size)\n",
      "Metrics: {'accuracy': 0.8898662913441239, 'precision': 0.6801128349788435, 'recall': 0.8483462350457425, 'f1': 0.7549710349146704, 'roc_auc': np.float64(0.9091636102377081)}\n"
     ]
    }
   ],
   "source": [
    "# Imports local to this cell to keep top-level minimal\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X_tr, y_tr, weights = get_train_data(BALANCING_MODE)\n",
    "print(f'KNN using training set: {X_tr.shape}, BALANCING_MODE={BALANCING_MODE}')\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=15, weights='distance', n_jobs=-1)\n",
    "metrics, t_fit, t_pred = time_model_fit_predict(knn, X_tr, y_tr, X_test, y_test)\n",
    "\n",
    "print(f\"Fit time:  {t_fit:.2f}s (KNN fit is typically trivial)\")\n",
    "print(f\"Pred time: {t_pred:.2f}s (KNN prediction scales with train size)\")\n",
    "print('Metrics:', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5232dc78",
   "metadata": {},
   "source": [
    "### Run: Decision Tree (timed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb9ddd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree using training set: (90944, 22), BALANCING_MODE=smote\n",
      "Fit time:  0.96s\n",
      "Pred time: 0.01s\n",
      "Metrics: {'accuracy': 0.926460239268121, 'precision': 0.8016112789526687, 'recall': 0.840253342716397, 'f1': 0.82047758117162, 'roc_auc': np.float64(0.8941326530612246)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_tr, y_tr, weights = get_train_data(BALANCING_MODE)\n",
    "print(f'DecisionTree using training set: {X_tr.shape}, BALANCING_MODE={BALANCING_MODE}')\n",
    "\n",
    "params = {'random_state': 42, 'max_depth': None}\n",
    "if BALANCING_MODE == 'class_weights' and weights is not None:\n",
    "    params['class_weight'] = weights\n",
    "\n",
    "dt = DecisionTreeClassifier(**params)\n",
    "metrics, t_fit, t_pred = time_model_fit_predict(dt, X_tr, y_tr, X_test, y_test)\n",
    "\n",
    "print(f\"Fit time:  {t_fit:.2f}s\")\n",
    "print(f\"Pred time: {t_pred:.2f}s\")\n",
    "print('Metrics:', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c82e9ec",
   "metadata": {},
   "source": [
    "### Run: Random Forest (timed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3e5db76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest using training set: (90944, 22), BALANCING_MODE=smote\n",
      "Fit time:  9.53s\n",
      "Pred time: 0.16s\n",
      "Metrics: {'accuracy': 0.9482054890921886, 'precision': 0.9000759878419453, 'recall': 0.8335679099225898, 'f1': 0.865546218487395, 'roc_auc': np.float64(0.930210720265684)}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "X_tr, y_tr, weights = get_train_data(BALANCING_MODE)\n",
    "print(f'RandomForest using training set: {X_tr.shape}, BALANCING_MODE={BALANCING_MODE}')\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 200,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "}\n",
    "# class weights supported: 'balanced' or dict\n",
    "if BALANCING_MODE == 'class_weights' and weights is not None:\n",
    "    params['class_weight'] = weights\n",
    "\n",
    "rf = RandomForestClassifier(**params)\n",
    "metrics, t_fit, t_pred = time_model_fit_predict(rf, X_tr, y_tr, X_test, y_test)\n",
    "\n",
    "print(f\"Fit time:  {t_fit:.2f}s\")\n",
    "print(f\"Pred time: {t_pred:.2f}s\")\n",
    "print('Metrics:', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a43614",
   "metadata": {},
   "source": [
    "## SECTION 5B: Toggle Balancing Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f31e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BALANCING_MODE = smote\n",
      "âœ“ SMOTE data prepared: (90944, 22)\n"
     ]
    }
   ],
   "source": [
    "# Set the balancing mode here and ensure needed data exists\n",
    "BALANCING_MODE = 'smote'  # options: 'none' | 'smote' | 'smote_tomek' | 'class_weights'\n",
    "print('BALANCING_MODE =', BALANCING_MODE)\n",
    "\n",
    "# Ensure balanced datasets when needed\n",
    "if BALANCING_MODE in ('smote', 'smote_tomek', 'class_weights'):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from imblearn.combine import SMOTETomek\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    import numpy as np\n",
    "\n",
    "    if 'X_train_smote' not in globals() and BALANCING_MODE in ('smote', 'smote_tomek'):\n",
    "        smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        print('âœ“ SMOTE data prepared:', X_train_smote.shape)\n",
    "\n",
    "    if 'X_train_smo_tomek' not in globals() and BALANCING_MODE == 'smote_tomek':\n",
    "        smo_tomek = SMOTETomek(random_state=42)\n",
    "        X_train_smo_tomek, y_train_smo_tomek = smo_tomek.fit_resample(X_train, y_train)\n",
    "        print('âœ“ SMOTETomek data prepared:', X_train_smo_tomek.shape)\n",
    "\n",
    "    if 'class_weight_dict' not in globals() and BALANCING_MODE == 'class_weights':\n",
    "        classes = np.unique(y_train)\n",
    "        class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "        class_weight_dict = {int(cls): float(w) for cls, w in zip(classes, class_weights)}\n",
    "        print('âœ“ class_weight_dict prepared:', class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542a7ec",
   "metadata": {},
   "source": [
    "# Summary: Data Balancing + Supervised Training\n",
    "\n",
    "- Approach: Tomek Links + ENN applied only on training folds; RandomForest with `class_weight='balanced_subsample'`; evaluated via `StratifiedKFold`.\n",
    "\n",
    "- CV results (RF best): ROC-AUC â‰ˆ 0.917; PR-AUC â‰ˆ 0.889; F1 â‰ˆ 0.795 at default threshold.\n",
    "\n",
    "- Threshold tuning (maximize F1 via PR curve):\n",
    "  - Recommended threshold â‰ˆ 0.77â€“0.78 (mean 0.7715, std 0.0283).\n",
    "  - At tuned threshold: Precision â‰ˆ 0.929, Recall â‰ˆ 0.770, F1 â‰ˆ 0.842; ROC-AUC â‰ˆ 0.9166; PR-AUC â‰ˆ 0.8885.\n",
    "\n",
    "- Operational guidance:\n",
    "  - Prefer fewer false alarms â†’ raise threshold to ~0.80â€“0.81.\n",
    "  - Prefer fewer misses â†’ lower threshold to ~0.74â€“0.75.\n",
    "\n",
    "- Next steps: Holdout validation, export model + threshold, inference utility, feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "results_path = Path('f:/DATA/results/rf_tomek_enn_threshold_tuning.json')\n",
    "if results_path.exists():\n",
    "    data = json.loads(results_path.read_text())\n",
    "    agg = data.get('aggregated', {})\n",
    "    threshold = agg.get('threshold_mean', 0.77)\n",
    "    print(f\"Recommended RF threshold: {threshold:.4f}\")\n",
    "    print(\"Aggregated metrics @ tuned threshold:\")\n",
    "    for k in ('roc_auc_mean','pr_auc_mean','precision_mean','recall_mean','f1_mean'):\n",
    "        print(f\"  {k}: {agg.get(k):.4f}\")\n",
    "else:\n",
    "    print('Threshold tuning results JSON not found at:', results_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
